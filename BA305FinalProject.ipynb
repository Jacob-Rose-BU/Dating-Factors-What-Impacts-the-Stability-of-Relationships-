{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BA305 Final Project Python Notebook (How Do Couples Meet and Stay Together?)"
      ],
      "metadata": {
        "id": "WbyeRsY1bLhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amelia, John, Hannah, Jacob, Rohit\n",
        "\n",
        "Boston University\n",
        "\n",
        "BA305 Business Decision-Making with Data\n",
        "\n",
        "Professor. Karaca\n",
        "\n",
        "November 29th, 2023\n"
      ],
      "metadata": {
        "id": "GkdrdoMv9d5O"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGtI-UO5akNk"
      },
      "source": [
        "# 1. Data Upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjI5FbphyH-F",
        "outputId": "f3644a4f-de7e-4b61-cb40-63128bf0e08e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy.lib.function_base import average\n",
        "import math\n",
        "%matplotlib inline\n",
        "from sklearn import preprocessing\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm  # progress slider for \"for\" loops\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "!pip install keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from google.colab import drive\n",
        "from google.colab.data_table import DataTable as DT\n",
        "drive.mount('/content/drive')\n",
        "datingdf = pd.read_csv('/content/drive/My Drive/Colab Data/HCMST_ver_3.04.csv')\n",
        "datingdf.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA4q3J0afmI5"
      },
      "outputs": [],
      "source": [
        "#ORIGINAL DATASET\n",
        "\"\"\"pd.set_option('display.max_columns', None)\n",
        "datingdf.head()\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsUFsa7daq-k"
      },
      "source": [
        "# 2. Data Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmoT7LzMtIBv"
      },
      "outputs": [],
      "source": [
        "partnereddf = datingdf.loc[(datingdf['qflag'] == 'partnered')]\n",
        "partnereddf = partnereddf[[\"s1\", \"caseid_new\", \"respondent_race\", \"partner_race\", \"ppage\", \"q9\", \"respondent_yrsed\", \"partner_yrsed\", \"same_sex_couple\", \"q12\", \"pppartyid3\",\"relationship_quality\", \"parental_approval\",\"w5_broke_up\",\"papreligion\", \"q7b\", \"w4_broke_up\", \"w2_broke_up\", \"w3_broke_up\", \"how_long_relationship\", \"hhinc\", \"children_in_hh\"]]\n",
        "partnereddf = partnereddf.rename(columns={\"s1\": \"married\",\"ppage\": \"AgeofResp\", \"q9\": \"AgeofPartner\", \"respondent_yrsed\":\"EDofResp\", \"partner_yrsed\":\"EDofPartner\", \"q12\": \"PartnerPoliticalParty\", \"pppartyid3\":\"RespPoliticalParty\", \"ppmarit\":\"LivingArrangement\", \"papreligion\":\"partnerreligion\", \"q7b\":\"respondentreligion\", \"hhinc\": \"HouseholdIncome\", \"children_in_hh\": \"kids\"})\n",
        "\n",
        "partnereddf2 = datingdf.loc[(datingdf['qflag'] == 'partnered')]\n",
        "partnereddf2 = partnereddf2[[\"s1\", \"caseid_new\", \"respondent_race\", \"partner_race\", \"ppage\", \"q9\", \"respondent_yrsed\", \"partner_yrsed\", \"same_sex_couple\", \"q12\", \"pppartyid3\",\"relationship_quality\", \"parental_approval\",\"w5_broke_up\",\"papreligion\", \"q7b\", \"w4_broke_up\", \"w2_broke_up\", \"w3_broke_up\", \"how_long_relationship\", \"hhinc\", \"children_in_hh\", \"how_long_ago_first_cohab\", \"q32_internet\", \"how_long_ago_first_met\"]]\n",
        "partnereddf2 = partnereddf2.rename(columns={\"q32_internet\":\"internetmet\", \"s1\": \"married\",\"ppage\": \"AgeofResp\", \"q9\": \"AgeofPartner\", \"respondent_yrsed\":\"EDofResp\", \"partner_yrsed\":\"EDofPartner\", \"q12\": \"PartnerPoliticalParty\", \"pppartyid3\":\"RespPoliticalParty\", \"ppmarit\":\"LivingArrangement\", \"papreligion\":\"partnerreligion\", \"q7b\":\"respondentreligion\", \"hhinc\": \"HouseholdIncome\", \"children_in_hh\": \"kids\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ic5686TLUBp"
      },
      "source": [
        "### a. Functions For Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDcX3Xbc3zZU"
      },
      "outputs": [],
      "source": [
        "#Fill in Null Values & Rename Columns\n",
        "def nullfill(df):\n",
        "  avglengthrelationship = df['how_long_relationship'].mean()\n",
        "  df['how_long_relationship'].fillna(avglengthrelationship, inplace=True)\n",
        "  #df = df.loc[(df[\"how_long_relationship\"] <= 20)]\n",
        "  df['AgeofPartner'].fillna(df['AgeofResp'], inplace=True)\n",
        "  df[\"partner_race\"].fillna(df[\"respondent_race\"], inplace=True)\n",
        "  df[\"respondent_race\"].fillna(df[\"partner_race\"], inplace=True)\n",
        "  df['EDofPartner'].fillna(df['EDofResp'], inplace=True)\n",
        "  df['partnerreligion'].fillna(df['respondentreligion'], inplace=True)\n",
        "  df[\"agegap\"] = abs(df[\"AgeofResp\"] - df[\"AgeofPartner\"])\n",
        "  df[\"difrace\"] = df[\"respondent_race\"] == df[\"partner_race\"]\n",
        "  df[\"haskids\"] = (df[\"kids\"] > 0)\n",
        "  df[\"difpoliticalparty\"] = df[\"PartnerPoliticalParty\"] == df[\"RespPoliticalParty\"]\n",
        "  return df\n",
        "\n",
        "\n",
        "#Create Dummy Variables\n",
        "def DummyVariables(df):\n",
        "  df = pd.concat([df, pd.get_dummies(df['same_sex_couple'])], axis=1)\n",
        "  df = pd.concat([df, pd.get_dummies(df['parental_approval'], prefix = \"ParentApproval\")], axis=1)\n",
        "  df[\"educationdifference\"] = abs(df[\"EDofResp\"] - df[\"EDofPartner\"])\n",
        "  df = pd.concat([df, pd.get_dummies(df['relationship_quality'],prefix = \"RelationshipQuality\")], axis=1)\n",
        "  df[\"difreligion\"] = df[\"partnerreligion\"] == df[\"respondentreligion\"]\n",
        "  df['w2_broke_up'].fillna(df['w3_broke_up'], inplace=True)\n",
        "  df['w2_broke_up'].fillna(df['w4_broke_up'], inplace=True)\n",
        "  df['w2_broke_up'].fillna(df['w5_broke_up'], inplace=True)\n",
        "  df['w3_broke_up'].fillna(df['w4_broke_up'], inplace=True)\n",
        "  df['w4_broke_up'].fillna(df['w5_broke_up'], inplace=True)\n",
        "  df = pd.concat([df, pd.get_dummies(df['w2_broke_up'], prefix = \"1year\")], axis=1) #FIXTHISFIX\n",
        "  df = pd.concat([df, pd.get_dummies(df['w3_broke_up'], prefix = \"2year\")], axis=1) #FIXTHISFIX\n",
        "  df = pd.concat([df, pd.get_dummies(df['w4_broke_up'], prefix = \"3year\")], axis=1) #FIXTHISFIX\n",
        "  df = pd.concat([df, pd.get_dummies(df['w5_broke_up'], prefix = \"4year\")], axis=1)\n",
        "  df = pd.concat([df, pd.get_dummies(df['married'])], axis=1)\n",
        "  df = df.rename(columns={\"yes, i am married\": \"married\"})\n",
        "  return df\n",
        "\n",
        "\n",
        "def changebrokeup(df):\n",
        "    #df['2year_broke up'].fillna(1, inplace=True)\n",
        "    df['2year_broke up'] = np.where(df['1year_broke up']==1, 1, df['2year_broke up'])\n",
        "    df['3year_broke up'] = np.where(df['2year_broke up']==1, 1, df['3year_broke up'])\n",
        "    df['4year_broke up'] = np.where(df['3year_broke up']==1, 1, df['4year_broke up'])\n",
        "    return df\n",
        "\n",
        "\n",
        "#CUT THE DATASET TO BE NEW COLUMNS ONLY FOR TESTING\n",
        "def convert_to_type(df):\n",
        "  df[\"difreligion\"] = df[\"difreligion\"].astype(int)\n",
        "  df[\"difrace\"] = df[\"difrace\"].astype(int)\n",
        "  df[\"difpoliticalparty\"] = df[\"difpoliticalparty\"].astype(int)\n",
        "  #df[\"haskids\"] = df[\"haskids\"].astype(int)\n",
        "  return df\n",
        "\n",
        "\n",
        "\n",
        "#print columns for datasets\n",
        "def printcol(df):\n",
        "  for col in df.columns:\n",
        "    print(col)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TELOmaPLfLu"
      },
      "source": [
        "### b. Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJkc_QvoLd6P"
      },
      "outputs": [],
      "source": [
        "partnereddf = nullfill(partnereddf)\n",
        "test1year = DummyVariables(partnereddf)\n",
        "test1year = changebrokeup(test1year)\n",
        "\n",
        "#THIS DATASET IS FOR 4 YEAR BROKE UP\n",
        "testing4dataset = test1year.iloc[:, 19:]\n",
        "testing4dataset = testing4dataset.drop(['different sex couple', \"1year_broke up\", \"3year_broke up\", \"2year_broke up\", \"kids\",\n",
        "                          \"1year_partner passed away\",\"3year_partner passed away\",\"2year_partner passed away\", \"4year_partner deceased\",\"3year_still together\", \"1year_partner deceased\", \"3year_partner deceased\",\n",
        "                            \"4year_still together\",\t\"1year_still together\",\t\"2year_partner deceased\",\t\"2year_still together\", \"no, i am not married\", \"ParentApproval_don't approve or don't know\"], axis = 1)\n",
        "testing4dataset = testing4dataset.rename(columns={\"4year_broke up\": \"Study_Break_Up\"})\n",
        "testing4dataset = convert_to_type(testing4dataset)\n",
        "\n",
        "#THIS DATASET IS FOR TESTING MORE SIGNIFICANT VARIABLES\n",
        "partnereddf2 = nullfill(partnereddf2)\n",
        "test1year2 = DummyVariables(partnereddf2)\n",
        "test1year2 = changebrokeup(test1year2)\n",
        "testing4dataset2 = test1year2.iloc[:, 19:]\n",
        "avgcohab = testing4dataset2['how_long_ago_first_cohab'].mean()\n",
        "testing4dataset2['how_long_ago_first_cohab'].fillna(avgcohab, inplace=True)\n",
        "avgmet = testing4dataset2['how_long_ago_first_met'].mean()\n",
        "testing4dataset2['how_long_ago_first_met'].fillna(avgmet, inplace=True)\n",
        "testing4dataset2[\"internetmet\"].fillna(0, inplace=True)\n",
        "testing4dataset2 = testing4dataset2.drop([\"educationdifference\", \"haskids\", 'different sex couple', \"1year_broke up\", \"3year_broke up\", \"2year_broke up\", \"kids\",\n",
        "                       \"1year_partner passed away\",\"3year_partner passed away\",\"2year_partner passed away\", \"4year_partner deceased\",\"3year_still together\", \"1year_partner deceased\", \"3year_partner deceased\",\n",
        "                       \"4year_still together\", \"1year_still together\",\t\"2year_partner deceased\",\t\"2year_still together\", \"no, i am not married\", \"ParentApproval_don't approve or don't know\"], axis = 1)\n",
        "testing4dataset2 = testing4dataset2.rename(columns={\"4year_broke up\": \"Study_Break_Up\"})\n",
        "testing4dataset2 = convert_to_type(testing4dataset2) #WON'T RUN UNLESS HAS KIDS IS #'d out\n",
        "testing4dataset2.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MF15RcIyuUd"
      },
      "outputs": [],
      "source": [
        "## adding a binned and unbinned version of the df so you can use it for NB and the rest of the applicaitons\n",
        "## making the dataframe to test the education question I asked down a bunch of kernels\n",
        "unbinned_df = testing4dataset\n",
        "for_edu = unbinned_df.copy(deep = False)\n",
        "unbinned_df.head().to_csv('/content/drive/My Drive/Colab Data/unbinned_df_head.csv')\n",
        "unbinned_df2 = testing4dataset2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3DSfjHEtbQr"
      },
      "outputs": [],
      "source": [
        "#TEST TO SEE HOW MANY TRUE BREAK UPS THERE ARE\n",
        "print(unbinned_df[\"Study_Break_Up\"].value_counts()[1])\n",
        "print(unbinned_df2[\"Study_Break_Up\"].value_counts()[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09w-gazFimET"
      },
      "outputs": [],
      "source": [
        "print(\"------------ DATASET VARIABLES --------------\")\n",
        "printcol(unbinned_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ar6UaZjLkIB"
      },
      "source": [
        "### c. Export Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyasPiVq7Jvt"
      },
      "outputs": [],
      "source": [
        "unbinned_df.to_csv('/content/drive/My Drive/Colab Data/unbinned_df.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUxyUs2lVCwY"
      },
      "source": [
        "### d. Binning for Naive Bayes\n",
        "#### Credit Section Chatgpt4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaLBSK35LCxh"
      },
      "outputs": [],
      "source": [
        "## binning this one for NB and will also make a copy to Google drive\n",
        "## pasting the code for the binning function here so its easier to see what you're doing\n",
        "\n",
        "## this is becoming 'yes_edu_dif' because the binning of this variable was so hard because education is numeric but there isn't a 1:1 dif between levels\n",
        "## having it just be a boolean is so much better\n",
        "\n",
        "## ****** Got this through Chatgpt4\n",
        "\n",
        "unbinned_df['yes_edu_dif'] = (unbinned_df['educationdifference'] != 0).astype(int)\n",
        "\n",
        "# defining function to create equal proportioned bins for naive bayes\n",
        "def binning_for_NB(df, column_name, n_bins):\n",
        "\n",
        "    # checking if the column even is in the dataframe\n",
        "    if column_name not in df.columns:\n",
        "        raise ValueError(f\"'{column_name}' not found in dataframe columns.\")\n",
        "\n",
        "    # Sort the dataframe based on the specified column\n",
        "    # The values within the column name are placed in descending order\n",
        "    df_sorted = df.sort_values(by = column_name)\n",
        "\n",
        "    # Calculate the size of each bin (3009 / n_bins)\n",
        "    bin_size = math.ceil(len(df_sorted) / n_bins)\n",
        "\n",
        "    # Assign labels to bins based off of the range(n_bins)\n",
        "    bin_ranges = []\n",
        "    for i in range(n_bins):\n",
        "        start_idx = i * bin_size\n",
        "        end_idx = start_idx + bin_size\n",
        "\n",
        "        # Get the range for the current bin\n",
        "        start_value = round(df_sorted.iloc[start_idx][column_name])\n",
        "        if end_idx < len(df_sorted):\n",
        "            end_value = round(df_sorted.iloc[end_idx][column_name])\n",
        "        else:\n",
        "            end_value = round(df_sorted.iloc[-1][column_name])\n",
        "\n",
        "        # Ensure the bin ranges do not overlap due to rounding\n",
        "        if i > 0 and start_value <= bin_ranges[-1][1]:\n",
        "            start_value = bin_ranges[-1][1]\n",
        "\n",
        "        # Assign the range to each observation in the bin\n",
        "        bin_ranges.extend([(start_value, end_value)] * bin_size)\n",
        "\n",
        "    # The last bin might have fewer observations than bin_size, so adjust the labels accordingly\n",
        "    bin_ranges = bin_ranges[:len(df_sorted)]\n",
        "\n",
        "    # Convert bin ranges to string format for labeling\n",
        "    bin_labels = [f\"[{start}, {end})\" for start, end in bin_ranges]\n",
        "\n",
        "    # Add the bin labels to the dataframe\n",
        "    df_sorted[f\"{column_name}_bins\"] = bin_labels\n",
        "\n",
        "    # Create new columns for each bin range\n",
        "    for bin_range in df_sorted[f\"{column_name}_bins\"].unique():\n",
        "        col_name = f\"{column_name}_{bin_range}\"\n",
        "        df_sorted[col_name] = (df_sorted[f\"{column_name}_bins\"] == bin_range).astype(int)\n",
        "\n",
        "    # Restore the original order of the dataframe\n",
        "    df = df_sorted.sort_index()\n",
        "\n",
        "    return df\n",
        "\n",
        "    ## every single new binned column will have an equal proportion of observations within them with this code for naive bayes (- John)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrVVzn3CIRAl"
      },
      "source": [
        "### e. Making Final Binned Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_hyKWLDsRDK"
      },
      "outputs": [],
      "source": [
        "## making a new intermediate dataframe to not fuck with the unbinned one\n",
        "## calling it \"unbinned_df_NB\"\n",
        "\n",
        "## binning length of relationship and removing\n",
        "unbinned_df_NB = binning_for_NB(unbinned_df, 'how_long_relationship', 8)\n",
        "unbinned_df_NB = unbinned_df_NB.drop(columns = [\"how_long_relationship_bins\", \"how_long_relationship\"])\n",
        "\n",
        "## binning age gap in relatinship\n",
        "unbinned_df_NB = binning_for_NB(unbinned_df_NB, 'agegap', 6)\n",
        "unbinned_df_NB = unbinned_df_NB.drop(columns = [\"agegap_bins\", \"agegap\"])\n",
        "\n",
        "## binning household income\n",
        "unbinned_df_NB = binning_for_NB(unbinned_df_NB, 'HouseholdIncome', 12)\n",
        "unbinned_df_NB = unbinned_df_NB.drop(columns = [\"HouseholdIncome_bins\", \"HouseholdIncome\"])\n",
        "\n",
        "## removing the final random leftover columns that shouldnt be in with the binned naive bayes dataframe\n",
        "binned_NB = unbinned_df_NB.drop(columns = [\"educationdifference\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMebXNumIl2k"
      },
      "source": [
        "### f. Showing Binned vs Unbinned Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZxHJMqBsRqp"
      },
      "outputs": [],
      "source": [
        "## now we have the binned_NB for the Naive Bayes classification model\n",
        "binned_NB.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K22gkoZmsR3l"
      },
      "outputs": [],
      "source": [
        "## and we have unbinned_df for all other classification models\n",
        "unbinned_df.head(10)\n",
        "#unbinned_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJbUFSndXB8c"
      },
      "source": [
        "# 3. Model Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lctiBvE6agER"
      },
      "source": [
        "## a. Naive Bayes Classifier Setup and Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPF8VI7Wil0k"
      },
      "outputs": [],
      "source": [
        "#Naive Bayes Bernoulli Classifier\n",
        "\n",
        "# Import our usual packages...\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import statistics\n",
        "from pandas.core.frame import DataFrame\n",
        "\n",
        "# Import some useful packages from scikit-learn\n",
        "from sklearn import naive_bayes, preprocessing\n",
        "from sklearn.naive_bayes import MultinomialNB # The Naive Bayes algo\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U33fHtkCfxH3"
      },
      "outputs": [],
      "source": [
        "## Naive Bayes Bernoulli Classifier Results\n",
        "## Using the binned_NB dataframe for this\n",
        "\n",
        "def NaiveBayesBer(df, variable):\n",
        "\n",
        "  df['target'] = df[variable]\n",
        "\n",
        "  y = df[\"target\"]\n",
        "\n",
        "  X = df.drop(['target', variable], axis = 1)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0, stratify = y)\n",
        "  print('Training set:', X_train.shape, 'Testing set:', X_test.shape)\n",
        "\n",
        "  BernoulliNBModel = naive_bayes.BernoulliNB()\n",
        "  BernoulliNBModel.fit(X_train, y_train)\n",
        "\n",
        "  BernoulliNBModel.class_count_\n",
        "\n",
        "  y_pred_test = BernoulliNBModel.predict(X_test)\n",
        "  y_pred_train = BernoulliNBModel.predict(X_train)\n",
        "\n",
        "#y_pred_train = full_clf.predict(X_train)\n",
        "#y_pred_test = full_clf.predict(X_test)\n",
        "\n",
        "  print(confusion_matrix(y_test, y_pred_test))\n",
        "  print(\"accuracy for training\", accuracy_score(y_train, y_pred_train))\n",
        "  print(\"accuracy for testing\", accuracy_score(y_test, y_pred_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF64qjGH-HZH"
      },
      "outputs": [],
      "source": [
        "NaiveBayesBer(binned_NB, \"Study_Break_Up\")\n",
        "\n",
        "binned_NB.head()\n",
        "\n",
        "## this is the only code needed use for this df so theres really no need to drop any of the variables afterwards\n",
        "## both 'target' and 'study_break_up' are present but the defining function makes it so only one is used for classication and the other isnt looked at\n",
        "## binned_NB = binned_NB.drop(['target'], axis = 1) - This line was up above but I kinda feel like its not doing anything\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCpUCqX4ayb5"
      },
      "source": [
        "## b. PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thO4LrWka1LT"
      },
      "outputs": [],
      "source": [
        "def heatmap(corr_mat):\n",
        "  plt.figure(figsize = (14,7))\n",
        "  sns.heatmap(corr_mat, annot = True, fmt = \".1f\", vmin = -1, vmax = 1, cmap = 'RdBu');\n",
        " # sns.heatmap(corr_mat, annot = True, fmt = \".1f\", vmin = -1, vmax = 1, cmap = 'Reds');\n",
        " # sns.heatmap(corr_mat, annot = True, fmt = \".1f\", vmin = -1, vmax = 1, cmap = 'Greys');\n",
        "\n",
        "def scree(df, eig):\n",
        "\n",
        "  # scree plot of eigenvalues\n",
        "  # define the x values, i.e., components\n",
        "  xvals = np.arange(df.shape[1]);\n",
        "  #figure size\n",
        "  plt.figure(figsize=(10,5))\n",
        "  #plot in red color\n",
        "  plt.plot(xvals, eig, 'ro-', linewidth=1)\n",
        "  #set ticks to every unit\n",
        "  plt.xticks(xvals)\n",
        "\n",
        "  #add labels...\n",
        "  plt.title('Scree Plot')\n",
        "  plt.xlabel('Principal Component')\n",
        "  plt.ylabel('Eigenvalue')\n",
        "\n",
        "  #add a horizontal line in blue for latent root criterion\n",
        "  plt.axhline(y=1, color='b', linestyle='--')\n",
        "\n",
        "\n",
        "def runPCA(df):\n",
        "  heatmap(corr_mat)\n",
        "\n",
        "  # Scaling Standardization (0 mean, unit variance) is done via the sklearn.preprocessing scale() function\n",
        "  pcs = PCA()\n",
        "  pcs.fit(preprocessing.scale(df))\n",
        "\n",
        "  # view the importance of principal components\n",
        "  pcsSummary_df = pd.DataFrame({\n",
        "              'Proportion of variance': pcs.explained_variance_ratio_,\n",
        "              'Cumulative proportion': np.cumsum(pcs.explained_variance_ratio_)\n",
        "              })\n",
        "  pcsSummary_df.round(3)\n",
        "\n",
        "\n",
        "  eig=pcs.explained_variance_.round(2)\n",
        "  print(eig)\n",
        "\n",
        "  scree(df, eig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWy19bpKGK8A"
      },
      "outputs": [],
      "source": [
        "## using the unbinned_df for this one\n",
        "## need to remove \"educationdifference\" from this... or could we see if having a binary classifier is better than a \"educationdifference\"? like having two dif dataframes\n",
        "## Ill actually just make a copy of the df and do that... might be cool\n",
        "\n",
        "column_to_remove = \"educationdifference\"\n",
        "if column_to_remove in binned_NB.columns:\n",
        "    binned_nb.drop(column_to_remove, axis = 1, inplace = True)\n",
        "\n",
        "corr_mat = unbinned_df.corr()\n",
        "corr_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ovM29h2G3vz"
      },
      "outputs": [],
      "source": [
        "#PCA FOR unbinned_df\n",
        "\n",
        "runPCA(unbinned_df)\n",
        "\n",
        "## possibly look at combining some of the relationship quality variables like excellent and great"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMWSCXRybRO9"
      },
      "source": [
        "## c. K Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKn6Qe_Zbbua"
      },
      "outputs": [],
      "source": [
        "# Separate X (input features/aka predictors) from y (target)\n",
        "\n",
        "\n",
        "def RunKnearest(df, variable):\n",
        "  outcome = variable\n",
        "  predictors = list(df.columns)\n",
        "  predictors.remove(outcome)\n",
        "\n",
        "  # Store predictors and target into X and y, respectively\n",
        "  X = df[predictors]\n",
        "  y = df[outcome]\n",
        "\n",
        "  X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.3, random_state=0, stratify=y)\n",
        "  print('Training set:', X_train.shape, 'Testing set:', X_test.shape)\n",
        "\n",
        "  # Standardize training and testing features using 'StandardScaler()'\n",
        "  # (a slightly different method than what we did in the PCA lab)\n",
        "\n",
        "  # the first line defines the scaling object\n",
        "  scaler = preprocessing.StandardScaler()\n",
        "\n",
        "  # the second line specifies which data to use to compute means and variances\n",
        "  scaler.fit(X_train)\n",
        "  # important: in this step, you should fit the scaler only to training data,\n",
        "  # and not the testing data. We assume testing data is never available to us\n",
        "  # in the training stage\n",
        "\n",
        "  # the third line scales the data using the means and variances computed in the\n",
        "  # previous step\n",
        "  X_train_scaled = scaler.transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "  # Note, there is no need to scale the target y variable, since this is what\n",
        "  # we are trying to predict\n",
        "  # Run the k-NN model with a random guess about the neighboors, set k=1 for instance\n",
        "  knn = KNeighborsClassifier(n_neighbors=1)\n",
        "  # Specify the training features (X_train) and the outcome they lead to (y_train)\n",
        "  # Important: only use the training data at this step. Do not use test data.\n",
        "  knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "  # Now that the model is done, we can use it to predict whether the new customers\n",
        "  # from the testing data, will accept a loan or not. For this, we feed the\n",
        "  # testing features X_test into the prediction function.\n",
        "  y_pred = knn.predict(X_test_scaled)\n",
        "  print('Accuracy for 1 neighbor:', accuracy_score(y_test, y_pred))\n",
        "  print()\n",
        "\n",
        "  results = []\n",
        "  for k in tqdm(range(1, 51, 1)):\n",
        "      knn = KNeighborsClassifier(n_neighbors=k).fit(X_train_scaled, y_train)\n",
        "\n",
        "      # create a dictionary to store the results\n",
        "      results.append({\n",
        "          'k': k,\n",
        "          'accuracy': accuracy_score(y_test, knn.predict(X_test_scaled))\n",
        "      })\n",
        "\n",
        "  # convert results to a pandas dataframe for better visualization\n",
        "  results_df = pd.DataFrame(results)\n",
        "  #print(results_df)\n",
        "  print(results_df)\n",
        "\n",
        "  max_val = results_df['accuracy'].max()\n",
        "  max_val_idx = results_df['accuracy'].idxmax()\n",
        "\n",
        "  knn = KNeighborsClassifier(n_neighbors= results_df['k'][max_val_idx])\n",
        "  knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "  pred_y_train = knn.predict(X_train_scaled)\n",
        "\n",
        "  pred_y_test = knn.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "\n",
        "  print()\n",
        "  print(\"K Value\", (max_val_idx + 1))\n",
        "  print(confusion_matrix(y_test, pred_y_test))\n",
        "  print('Accuracy for test', max,':', accuracy_score(y_test, pred_y_test))\n",
        "\n",
        "\n",
        "  print()\n",
        "  print(confusion_matrix(y_train, pred_y_train))\n",
        "  print('Accuracy for train', max,':', accuracy_score(y_train, pred_y_train))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPIODzvkCfLj"
      },
      "outputs": [],
      "source": [
        "#RUN K nearest neighbors for unbinned_df\n",
        "\n",
        "RunKnearest(unbinned_df, 'Study_Break_Up')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbvavV71ESox"
      },
      "source": [
        "## d. Decision Tree\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWJcPFwQIHyv"
      },
      "outputs": [],
      "source": [
        "# https://github.com/parrt/dtreeviz/blob/master/notebooks/dtreeviz_sklearn_visualisations.ipynb\n",
        "%%capture\n",
        "!pip install dtreeviz\n",
        "import dtreeviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXADb56_JKgr"
      },
      "outputs": [],
      "source": [
        "# Import the Random Forest (RF) classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Visualize the full tree via \"plot_tree\" function\n",
        "from sklearn import tree\n",
        "print(\"gi\")\n",
        "def tree_vis(tree):\n",
        "   # First, re-size the figure via matplotlib(otherwise it will be too small)\n",
        "  plt.figure(figsize=(15,10))\n",
        "  # Then call plot_tree() function\n",
        "  # the 'filled' option generates colors in the nodes\n",
        "  tree.plot_tree(tree, filled=True);\n",
        "\n",
        "def plot(a, train_scores, test_scores, x, y):\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.set_xlabel(\"alpha\")\n",
        "  ax.set_ylabel(\"accuracy\")\n",
        "  plt.xlim(0,0.010)\n",
        "  plt.ylim(x,y)\n",
        "  ax.plot(a, train_scores, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n",
        "  ax.plot(a, test_scores, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\n",
        "  ax.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def DTmodel(X, y, aval, xplot, yplot):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
        "\n",
        "  full_clf = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "  full_clf.fit(X_train, y_train)\n",
        "\n",
        "  print('Number of nodes', full_clf.tree_.node_count)\n",
        "\n",
        "  # Feed input data to model to predict y output, for training data and test data, separately\n",
        "  y_pred_train = full_clf.predict(X_train)\n",
        "  y_pred_test = full_clf.predict(X_test)\n",
        "\n",
        "  # Confusion matrix of full tree on training and test sets\n",
        "  print(\"Confusion Matrix on train data (watch out for overfitting!):\")\n",
        "  print(\"Accuracy score of reduced tree on train data:\", accuracy_score(y_train, y_pred_train)*100, \"%\")\n",
        "  print(confusion_matrix(y_train, y_pred_train))\n",
        "\n",
        "  print(\"Confusion Matrix of full tree on test data:\")\n",
        "  print(\"Accuracy score of reduced tree on test data:\", accuracy_score(y_test, y_pred_test)*100, \"%\")\n",
        "  print(confusion_matrix(y_test, y_pred_test))\n",
        "\n",
        "  # Retrieve all the 'unique' values of penalty alpha and the impurity score\n",
        "  # they generate, from the full tree. We will use the cost_complexity_pruning_path() function\n",
        "  # To retrieve the alpha values, we need to call the option 'ccp_alphas'\n",
        "  alphas = full_clf.cost_complexity_pruning_path(X_train, y_train).ccp_alphas\n",
        "\n",
        "  clfs = []\n",
        "\n",
        "  for i in alphas:\n",
        "    my_clf = DecisionTreeClassifier(random_state=0, ccp_alpha=i)\n",
        "    my_clf.fit(X_train, y_train)\n",
        "    clfs.append(my_clf) #this line adds to the fitted tree to the clfs[] array\n",
        "\n",
        "    # Let's try to find the best alpha to use...\n",
        "    # We can plot the tree predictive accuracy as a function of alpha\n",
        "  train_scores = [accuracy_score(y_train, x.predict(X_train)) for x in clfs]\n",
        "  test_scores = [accuracy_score(y_test, x.predict(X_test)) for x in clfs]\n",
        "\n",
        "  plot(alphas, train_scores, test_scores, xplot, yplot)\n",
        "\n",
        "  final_clf = DecisionTreeClassifier(random_state=0, ccp_alpha=aval)\n",
        "  final_clf.fit(X_train, y_train)\n",
        "  # Confusion matrix of \"final\" tree\n",
        "  y_pred_final = final_clf.predict(X_test)\n",
        "\n",
        "  print(\"Accuracy score of reduced tree on test data :\", accuracy_score(y_test, y_pred_final)*100, \"%\")\n",
        "\n",
        "  print(\"Confusion Matrix of final reduced pruned tree on test data:\")\n",
        "  print(confusion_matrix(y_test, y_pred_final))\n",
        "  #print(y_pred_final)\n",
        "  # Five-fold cross-validation of the decision tree using cross_val_score function\n",
        "  # We're going to use the tree stored in 'clf' variable\n",
        "  accuracy_scores = cross_val_score(final_clf, X_train, y_train, cv=5)\n",
        "  print('Accuracy scores of each fold: ', [f'{acc:.3f}' for acc in accuracy_scores])\n",
        "  print('5-fold cross-validation mean accuracy:', round(accuracy_scores.mean(),3))\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "\n",
        "  # Extract importance values for each feature (column of X)\n",
        "  importances1 = final_clf.feature_importances_\n",
        "\n",
        "  # create a dataframe to store the values and their labels\n",
        "  df3 = pd.DataFrame({'feature': X_train.columns, 'importance': importances1})\n",
        "\n",
        "  # sort dataframe by descending order, showing the most important feature top\n",
        "  df3 = df3.sort_values('importance', ascending = False)\n",
        "\n",
        "  ##running random forests within this function\n",
        "\n",
        "  # Run the RF classifier, specifying the number of trees to generate\n",
        "  # Note, being careful about overfitting is not as critical\n",
        "  # when using random forest classifiers, given they randomize over\n",
        "  # the data and the feature columns\n",
        "  # n_estimators is the total number of different random trees to generate\n",
        "\n",
        "  rf = RandomForestClassifier(\n",
        "      n_estimators = 10000,\n",
        "      random_state = 0,\n",
        "      criterion = 'gini',\n",
        "      n_jobs = -1)\n",
        "  rf.fit(X_train, y_train)\n",
        "\n",
        "  print(\"Accuracy Score For Random Forest: \", accuracy_score(y_test, rf.predict(X_test))*100, \"%\")\n",
        "  print(confusion_matrix(y_test, rf.predict(X_test)))\n",
        "\n",
        "  # Extract importance values for each feature (column of X)\n",
        "  importances = rf.feature_importances_\n",
        "\n",
        "  # create a dataframe to store the values and their labels\n",
        "  df2 = pd.DataFrame({'feature': X_train.columns, 'importance': importances})\n",
        "\n",
        "  # sort dataframe by descending order, showing the most important feature top\n",
        "  df2 = df2.sort_values('importance', ascending = False)\n",
        "\n",
        "  # plot the importance of each feature\n",
        "  ax = df2.plot(kind = 'bar', x = 'feature')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2wwfpHVDGDb"
      },
      "outputs": [],
      "source": [
        "print(\"Decision Tree Model For Breaking up During the Study\")\n",
        "Xinput = unbinned_df.drop(columns = ['Study_Break_Up'])\n",
        "yinput = unbinned_df['Study_Break_Up']\n",
        "aval = .003\n",
        "DTmodel(Xinput, yinput, aval, .6, .9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Decision Tree Model For Breaking up During the Study TEST 2\")\n",
        "Xinput = unbinned_df2.drop(columns = ['Study_Break_Up'])\n",
        "yinput = unbinned_df2['Study_Break_Up']\n",
        "aval = .0039\n",
        "DTmodel(Xinput, yinput, aval, .6, .9)"
      ],
      "metadata": {
        "id": "NmpfyuiWx_EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzttVAixonYe"
      },
      "source": [
        "## e. Testing Same Sex Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqgU82Ycoqim"
      },
      "outputs": [],
      "source": [
        "ss4year = unbinned_df.loc[(unbinned_df['same-sex couple'] == 1)]\n",
        "hetero4year = unbinned_df.loc[(unbinned_df['same-sex couple'] == 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHGjg9PLz-9j"
      },
      "outputs": [],
      "source": [
        "print(\"4 year test Hetero\")\n",
        "NaiveBayesBer(hetero4year, \"Study_Break_Up\")\n",
        "hetero4year = hetero4year.drop(['target'], axis = 1)\n",
        "\n",
        "\n",
        "print(\"4 year test SS\")\n",
        "NaiveBayesBer(ss4year, \"Study_Break_Up\")\n",
        "ss4year = ss4year.drop(['target'], axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LG8IdiB2Q_9"
      },
      "source": [
        "## f. Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pg-NmrAC2V9a"
      },
      "outputs": [],
      "source": [
        "def NN2(df):\n",
        "  y = df['Study_Break_Up']\n",
        "  X = df.drop(['Study_Break_Up'], axis=1)\n",
        "\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  PredictorScaler=StandardScaler()\n",
        "  # Storing the fit object for later reference\n",
        "  PredictorScalerFit=PredictorScaler.fit(X)\n",
        "\n",
        "  # Generating the standardized values of X and y\n",
        "  X=PredictorScalerFit.transform(X)\n",
        "\n",
        "  # build a model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(16, input_shape=(X.shape[1],), activation='relu')) # Add an input shape! (features,)\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.summary()\n",
        "\n",
        "  # compile the model\n",
        "  model.compile(optimizer='Adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # early stopping callback\n",
        "  # This callback will stop the training when there is no improvement in\n",
        "  # the validation loss for 10 consecutive epochs.\n",
        "  es = EarlyStopping(monitor='val_accuracy',\n",
        "                                    mode='max', # don't minimize the accuracy!\n",
        "                                    patience=10,\n",
        "                                    restore_best_weights=True)\n",
        "\n",
        "  # now we just update our model fit call\n",
        "  history = model.fit(X,\n",
        "                      y,\n",
        "                      callbacks=[es],\n",
        "                      epochs=80, # you can set this to a big number!\n",
        "                      batch_size=10,\n",
        "                      validation_split=0.3,\n",
        "                      shuffle=True,\n",
        "                      verbose=1)\n",
        "  print(\"Test loss:\", score[0])\n",
        "  print(\"Test accuracy:\", score[1])\n",
        "\n",
        "def NN(df):\n",
        "\n",
        "  y = df['Study_Break_Up']\n",
        "  X = df.drop(['Study_Break_Up'], axis=1)\n",
        "\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  PredictorScaler=StandardScaler()\n",
        "  # Storing the fit object for later reference\n",
        "  PredictorScalerFit=PredictorScaler.fit(X)\n",
        "\n",
        "  # Generating the standardized values of X and y\n",
        "  X=PredictorScalerFit.transform(X)\n",
        "\n",
        "  # Split the data into training and testing set\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)\n",
        "\n",
        "\n",
        "\n",
        "  # Quick sanity check with the shapes of Training and Testing datasets\n",
        "  print(X_train.shape)\n",
        "  print(y_train.shape)\n",
        "  print(X_test.shape)\n",
        "  print(y_test.shape)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, activation='relu'))\n",
        "  model.add(Dense(8, activation='relu'))\n",
        "  model.add(Dense(8, activation='relu'))\n",
        "  model.add(Dense(8, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # compile the keras model\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test))\n",
        "\n",
        "  score = model.evaluate(X_test, y_test, verbose=0)\n",
        "  print(\"Test loss:\", score[0])\n",
        "  print(\"Test accuracy:\", score[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JTn8Xn58z2R"
      },
      "outputs": [],
      "source": [
        "NN(unbinned_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnJhDCQ1GX6s"
      },
      "outputs": [],
      "source": [
        "NN2(unbinned_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NN2(unbinned_df2)"
      ],
      "metadata": {
        "id": "Quzp6yxt5cRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Data Visualizations"
      ],
      "metadata": {
        "id": "vJcyxxqoZOYR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16OK3a26WoJ_"
      },
      "source": [
        "##a. Variables & Broke Up Relationships"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnh5bwnaWuQI"
      },
      "outputs": [],
      "source": [
        "unbinned_df ## using this cause its easier for right now\n",
        "\n",
        "corr_matrix = unbinned_df.corr()\n",
        "\n",
        "# Computing a normal correlation coefficient\n",
        "corr = unbinned_df.corr()[\"Study_Break_Up\"]\n",
        "\n",
        "# Compute the Pearson correlation coefficient\n",
        "pearson_corr = unbinned_df.corr(method='pearson')[\"Study_Break_Up\"]\n",
        "\n",
        "# Compute the Spearman correlation coefficient\n",
        "spearman_corr = unbinned_df.corr(method = 'spearman')[\"Study_Break_Up\"]\n",
        "\n",
        "# Compute the Kendall correlation coefficient\n",
        "kendall_corr = unbinned_df.corr(method = 'kendall')[\"Study_Break_Up\"]\n",
        "\n",
        "pearson_corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUDNS2G0WvHV"
      },
      "outputs": [],
      "source": [
        "# Convert to DataFrame and graph\n",
        "# Computing a normal correlation coefficient\n",
        "corr = df.corr()[\"Income\"]\n",
        "\n",
        "\n",
        "\n",
        "def corr_to_graph(df, type_corr):\n",
        "\n",
        "  # Convert to DataFrame\n",
        "  correlation_df = pd.Series(df).to_frame(name = \"Correlation\")\n",
        "\n",
        "  # Sort the correlations for better visualization\n",
        "  correlation_df_sorted = correlation_df.sort_values(by = \"Correlation\", ascending = True)\n",
        "\n",
        "  # Create a bar chart with numerical values\n",
        "  plt.figure(figsize = (10, 8))\n",
        "  bars = plt.barh(correlation_df_sorted.index, correlation_df_sorted['Correlation'], color = 'lightpink')\n",
        "\n",
        "  # Add the correlation values at the end of each bar\n",
        "  for bar in bars:\n",
        "      width = bar.get_width()\n",
        "      label_x_pos = bar.get_width() if bar.get_width() < 0 else bar.get_width() + 0.02\n",
        "      plt.text(label_x_pos, bar.get_y() + bar.get_height()/2, f'{width:.2f}', va = 'center')\n",
        "\n",
        "  plt.xlabel('Correlation Coefficient')\n",
        "  plt.title(f'{type_corr} Correlation with Outcome Variable')\n",
        "  plt.tight_layout()  # Adjust layout for better fit\n",
        "\n",
        "  # Show the chart with numerical values\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4emmTUWSW08r"
      },
      "outputs": [],
      "source": [
        "corr_to_graph(corr, '')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def corr_to_graph2(df, type_corr):\n",
        "\n",
        "  # Convert to DataFrame\n",
        "  correlation_df = pd.Series(df).to_frame(name = \"Correlation\")\n",
        "\n",
        "  # Sort the correlations for better visualization\n",
        "  correlation_df_sorted = correlation_df.sort_values(by = \"Correlation\", ascending = True)\n",
        "  correlation_df_sorted = correlation_df_sorted.loc[(abs(correlation_df_sorted['Correlation']) >= .1 )]\n",
        "\n",
        "  # Create a bar chart with numerical values\n",
        "  plt.figure(figsize = (10, 8))\n",
        "  bars = plt.barh(correlation_df_sorted.index, correlation_df_sorted['Correlation'], color = 'lightpink')\n",
        "\n",
        "  # Add the correlation values at the end of each bar\n",
        "  for bar in bars:\n",
        "      width = bar.get_width()\n",
        "      label_x_pos = bar.get_width() if bar.get_width() < 0 else bar.get_width() + 0.02\n",
        "      plt.text(label_x_pos, bar.get_y() + bar.get_height()/2, f'{width:.2f}', va = 'center')\n",
        "\n",
        "  plt.xlabel('Correlation Coefficient')\n",
        "  plt.title(f'{type_corr} Correlation with Study_Break_Up')\n",
        "  plt.tight_layout()  # Adjust layout for better fit\n",
        "\n",
        "  # Show the chart with numerical values\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "mkPXA50Bkvoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def change_break(df):\n",
        "  df = df.loc[(df['qflag'] == 'partnered')]\n",
        "  df['w2_broke_up'].fillna(df['w3_broke_up'], inplace=True)\n",
        "  df['w2_broke_up'].fillna(df['w4_broke_up'], inplace=True)\n",
        "  df['w2_broke_up'].fillna(df['w5_broke_up'], inplace=True)\n",
        "  df['w3_broke_up'].fillna(df['w4_broke_up'], inplace=True)\n",
        "  df['w4_broke_up'].fillna(df['w5_broke_up'], inplace=True)\n",
        "  df = pd.concat([df, pd.get_dummies(df['w2_broke_up'], prefix = \"1year\")], axis=1) #FIXTHISFIX\n",
        "  df = pd.concat([df, pd.get_dummies(df['w3_broke_up'], prefix = \"2year\")], axis=1) #FIXTHISFIX\n",
        "  df = pd.concat([df, pd.get_dummies(df['w4_broke_up'], prefix = \"3year\")], axis=1) #FIXTHISFIX\n",
        "  df = pd.concat([df, pd.get_dummies(df['w5_broke_up'], prefix = \"4year\")], axis=1)\n",
        "  df['2year_broke up'] = np.where(df['1year_broke up']==1, 1, df['2year_broke up'])\n",
        "  df['3year_broke up'] = np.where(df['2year_broke up']==1, 1, df['3year_broke up'])\n",
        "  df['4year_broke up'] = np.where(df['3year_broke up']==1, 1, df['4year_broke up'])\n",
        "  df = df.drop(['2year_broke up', '3year_broke up','1year_broke up', '4year_still together','3year_still together', '2year_still together', '1year_still together'], axis = 1)\n",
        "  df = df.rename(columns={\"4year_broke up\": \"Study_Break_Up\"})\n",
        "  return df\n",
        "\n",
        "df = change_break(datingdf)\n",
        "corrdf = df.corr()[\"Study_Break_Up\"]\n",
        "corr_to_graph2(corrdf, '')"
      ],
      "metadata": {
        "id": "EAt3uLWhaqnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b. Other"
      ],
      "metadata": {
        "id": "rfRiVmiladzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting occurrences of the binary variable across the x-axis fields\n",
        "counts = binned_NB.groupby(['how_long_relationship_[0, 2)', 'how_long_relationship_[2, 6)', 'how_long_relationship_[6, 9)', 'how_long_relationship_[9, 13)', 'how_long_relationship_[13, 18)',\n",
        "                            'how_long_relationship_[18, 26)', 'how_long_relationship_[26, 39)', 'how_long_relationship_[39, 76)'])['ParentApproval_approve'].sum().reset_index()\n",
        "\n",
        "# Creating a bar chart using Matplotlib\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(range(len(counts)), counts['ParentApproval_approve'], color='pink')\n",
        "\n",
        "#x_labels = ['{}_{}'.format(field1, field2, field3, field4, field5, field6, field7, field8) for field1, field2, field3, field4, field5, field6, field7, field8 in zip(counts['how_long_relationship_[0, 2)'],\n",
        "  #        counts['how_long_relationship_[2, 6)'], counts['how_long_relationship_[6, 9)'], counts['how_long_relationship_[9, 13)'], counts['how_long_relationship_[13, 18)'],\n",
        " #         counts['how_long_relationship_[18, 26)'], counts['how_long_relationship_[26, 39)'], counts['how_long_relationship_[39, 76)'])]\n",
        "\n",
        "x_labels = ['{}{}{}'.format(\n",
        "        (counts.loc[i, 'how_long_relationship_[0, 2)']),\n",
        "        (counts.loc[i, 'how_long_relationship_[2, 6)']),\n",
        "        (counts.loc[i, 'how_long_relationship_[6, 9)']),\n",
        "        (counts.loc[i, 'how_long_relationship_[9, 13)']),\n",
        "        (counts.loc[i, 'how_long_relationship_[13, 18)']),\n",
        "        (counts.loc[i, 'how_long_relationship_[18, 26)']),\n",
        "        (counts.loc[i, 'how_long_relationship_[26, 39)']),\n",
        "        (counts.loc[i, 'how_long_relationship_[39, 76)'])\n",
        "        )\n",
        "    for i in range(len(counts))]\n",
        "\n",
        "\n",
        "x_labels2 = [\"0 - 2\", \"2 - 6\", \"6 - 9\", \"9 - 13\", \"13 - 18\", \"18 - 26\", \"26 - 39\", \"39 - 76\"]\n",
        "\n",
        "\n",
        "# Adding x-axis labels\n",
        "plt.xlabel('Relationship Length in Years')\n",
        "plt.ylabel('Parental Approval')\n",
        "plt.title('Bar Chart of Parental Approval Across Relationship Lengths')\n",
        "\n",
        "# Setting x-axis ticks and labels\n",
        "#plt.xticks(range(len(counts)), x_labels)\n",
        "\n",
        "# Rotating x-axis labels for better readability if needed\n",
        "plt.xticks(range(len(counts)), x_labels2)\n",
        "\n",
        "# Adding data labels on top of bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, yval, round(yval, 2), va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "du5BxLzXbam6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Breakup_sum= binned_NB['Study_Break_Up'].sum()\n",
        "Married_sum= binned_NB['married'].sum()"
      ],
      "metadata": {
        "id": "813clPLRqx5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [['Breakup_sum' , int(Breakup_sum)],\n",
        " ['Married_sum' , int(Married_sum)]]\n"
      ],
      "metadata": {
        "id": "2r5uDqsWqHqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = ['Relationship_Status','Count']  # Columns to be selected for the new DataFrame\n",
        "\n",
        "# Creating a new DataFrame from selected columns\n",
        "new_df = pd.DataFrame(data, columns= selected_columns)\n",
        "\n",
        "print(new_df)"
      ],
      "metadata": {
        "id": "IDog8bp4pIvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the bar chart\n",
        "plt.figure(figsize=(10, 6))  # Set the figure size\n",
        "plt.figure(figsize=(8, 6))  # Set the figure size (width, height)\n",
        "\n",
        "\n",
        "bars = plt.bar(new_df.Relationship_Status, new_df.Count, color='pink')  # Create the bar chart\n",
        "\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, yval, yval, ha='center', va='bottom')\n",
        "\n",
        "plt.xlabel('Relationship Status')  # Label for the x-axis\n",
        "plt.ylabel('Count')  # Label for the y-axis\n",
        "plt.title('Distribution of Relationship Status')  # Title for the chart\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_4PfZg0_oNv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_labels = ['{}{}{}{}{}{}{}'.format(\n",
        "        (counts.loc[i, 'how_long_relationship_[0, 2)']),\n",
        "        (counts.loc[i, 'how_long_relationship_[2, 6)']),\n",
        "        (counts.loc[i, 'how_long_relationship_[6, 9)']),\n",
        "        (counts.loc[i, 'how_long_relationship_[9, 13)']),\n",
        "        (counts.loc[i, 'how_long_relationship_[13, 18)']),\n",
        "        (counts.loc[i, 'how_long_relationship_[18, 26)']),\n",
        "        (counts.loc[i, 'how_long_relationship_[26, 39)']),\n",
        "        (counts.loc[i, 'how_long_relationship_[39, 76)'])\n",
        "        )\n",
        "    for i in range(len(counts))]"
      ],
      "metadata": {
        "id": "yEM4dR3Qs8ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "qj5Pq-NauWZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##unbinned_df\n",
        "\n",
        "# import required packages\n",
        "%matplotlib inline\n",
        "import matplotlib.pylab as plt\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import *\n",
        "\n",
        "# Define X and y\n",
        "y = unbinned_df['Study_Break_Up']\n",
        "X = unbinned_df.drop(columns=['Study_Break_Up'])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.3, random_state = 0, stratify = y)\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(penalty = \"none\", solver = 'lbfgs')\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on test data\n",
        "y_pred = lr.predict(X_test)"
      ],
      "metadata": {
        "id": "areCueexuVEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "# accuracy score\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "aAR-jOAtvn2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What if we want to change the default probability cutoff of 0.5?\n",
        "\n",
        "# Extract regressed probabilities using predict_proba\n",
        "p_pred = lr.predict_proba(X_test)[:,1]\n",
        "np.round(p_pred,3)"
      ],
      "metadata": {
        "id": "1VYGeIFzvvb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define new cutoff\n",
        "cutoff = 0.49\n",
        "y_pred_new = [1 if i > cutoff else 0 for i in p_pred]\n",
        "y_pred_new"
      ],
      "metadata": {
        "id": "K3feYU55vxRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix with different cutoff\n",
        "confusion_matrix(y_test,y_pred_new)"
      ],
      "metadata": {
        "id": "Dv2JFijTv5b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy score with different cutoff\n",
        "accuracy_score(y_test, y_pred_new)"
      ],
      "metadata": {
        "id": "pFTlUAKOv8UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store coefficients\n",
        "lr_int = lr.intercept_[0]\n",
        "lr_coef = lr.coef_[0]\n",
        "\n",
        "# print coefficients\n",
        "print('intercept ', lr_int)\n",
        "print(pd.DataFrame({'coeff': lr_coef}, index=X.columns))"
      ],
      "metadata": {
        "id": "2LHLEV5hwA2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print exponentiated Experience and Training coefficients\n",
        "print( math.exp(lr_coef[0]) )\n",
        "print( math.exp(lr_coef[1]) )"
      ],
      "metadata": {
        "id": "AqTN_ApMwDmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFOs4lFJSbjL"
      },
      "source": [
        "# 5. Archive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6LudBFDSvMf"
      },
      "source": [
        "\n",
        "Create Bins for Metric Variables and Get Dummies\n",
        "\n",
        "\n",
        "def CreateBin(df, abinval, lbinval, ebinval, ibinval):\n",
        "  df['agebin'] = pd.cut(df['agegap'], abinval)\n",
        "  df = pd.concat([df, pd.get_dummies(df['agebin'], prefix = \"Age_Gap_\")], axis=1)\n",
        "\n",
        "  df['how_long_relationship'] = pd.cut(df['how_long_relationship'], lbinval)\n",
        "  df = pd.concat([df, pd.get_dummies(df['how_long_relationship'], prefix = \"Relationship_Length_\")], axis=1)\n",
        "\n",
        "\n",
        "  df['educationdifference'] = pd.cut(df['educationdifference'], ebinval)\n",
        "  df = pd.concat([df, pd.get_dummies(df['educationdifference'], prefix = \"education_difference_\")], axis=1)\n",
        "\n",
        "  df['HouseholdIncome'] = pd.cut(df['HouseholdIncome'], ibinval)\n",
        "  df = pd.concat([df, pd.get_dummies(df['HouseholdIncome'], prefix = \"HouseholdIncome_\")], axis=1)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "\n",
        "THIS DATASET IS FOR THE 1 YEAR BROKE UP\n",
        " \"1year_broke up\"\n",
        "testing1dataset = test1year.iloc[:, 19:]\n",
        "testing1dataset  = testing1dataset.drop(['different sex couple', \"2year_broke up\", \"3year_broke up\", \"4year_broke up\",\n",
        "                           \"1year_partner passed away\",\"3year_partner passed away\",\"4year_partner deceased\",\"3year_still together\",\n",
        "                            \"4year_still together\",\t\"1year_still together\",\t\"2year_partner deceased\",\t\"2year_still together\", \"no, i am not married\", \"ParentApproval_don't approve or don't know\"], axis = 1)\n",
        "testing1dataset = convert_to_type(testing1dataset)\n",
        "\"agebin\" , \"educationdifference\",\n",
        "\n",
        "THIS DATASET IS FOR 2 YEAR BROKE UP\n",
        " \"2year_broke up\"\n",
        "testing2dataset = test1year.iloc[:, 23:]\n",
        "testing2dataset  = testing2dataset.drop([ \"1year_broke up\", \"3year_broke up\", \"4year_broke up\", 'different sex couple', \"3year_broke up\", \"4year_broke up\",\n",
        "                            \"1year_partner passed away\",\"3year_partner passed away\",\"4year_partner deceased\",\"3year_still together\",\n",
        "                          \"4year_still together\",\t\"1year_still together\",\t\"2year_partner deceased\",\t\"2year_still together\", \"no, i am not married\", \"ParentApproval_don't approve or don't know\"], axis = 1)\n",
        "testing2dataset = convert_to_type(testing2dataset)\n",
        "\"agebin\",\"educationdifference\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "THIS DATASET IS FOR ALL YEAR BROKE UP\n",
        "testing3dataset = test1year.iloc[:, 19:]\n",
        "testing3dataset  = testing3dataset.drop(['different sex couple', \"1year_broke up\", \"4year_broke up\", \"2year_broke up\",\n",
        "                            \"1year_partner passed away\",\"3year_partner passed away\",\"4year_partner deceased\",\"3year_still together\",\n",
        "                            \"4year_still together\",\t\"1year_still together\",\t\"2year_partner deceased\",\t\"2year_still together\", \"no, i am not married\", \"ParentApproval_don't approve or don't know\"], axis = 1)\n",
        "testing3dataset = convert_to_type(testing3dataset)\n",
        "\"agebin\",\"educationdifference\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "THIS DATASET IS FOR ALL YEAR BROKE UP\n",
        "testingalldataset = test1year.iloc[:, 19:]\n",
        "testingalldataset  = testingalldataset.drop(['different sex couple',\n",
        "                            \"1year_partner passed away\",\"3year_partner passed away\",\"4year_partner deceased\",\"3year_still together\",\n",
        "                            \"4year_still together\",\t\"1year_still together\",\t\"2year_partner deceased\",\t\"2year_still together\", \"no, i am not married\", \"ParentApproval_don't approve or don't know\"], axis = 1)\n",
        "testingalldataset = convert_to_type(testingalldataset)\n",
        "\"agebin\",\"educationdifference\",\n",
        "\n",
        "OG COLUMN NAMES\n",
        "for col in datingdf.columns:\n",
        "    print(col)\n",
        "\n",
        "print(testing1dataset['1year_broke up'].value_counts()[1])\n",
        "print(testing2dataset['2year_broke up'].value_counts()[1])\n",
        "print(testing3dataset['3year_broke up'].value_counts()[1])\n",
        "\n",
        "\n",
        "printcol(testing1dataset)\n",
        "print(\"------------NEW DATASET--------------\")\n",
        "printcol(testing2dataset)\n",
        "print(\"------------NEW DATASET--------------\")\n",
        "printcol(testingalldataset)\n",
        "\n",
        "print(\"1 year test\")\n",
        "NaiveBayesBer(testing1dataset, \"1year_broke up\")\n",
        "testing1dataset = testing1dataset.drop(['target'], axis = 1)\n",
        "\n",
        "print(\"2 year test\")\n",
        "NaiveBayesBer(testing2dataset, \"2year_broke up\")\n",
        "testing2dataset = testing2dataset.drop(['target'], axis = 1)\n",
        "\n",
        "print(\"1 year test Hetero\")\n",
        "NaiveBayesBer(hetero1year, \"1year_broke up\")\n",
        "hetero1year = hetero1year.drop(['target'], axis = 1)\n",
        "\n",
        "\n",
        "print(\"1 year test SS\")\n",
        "NaiveBayesBer(ss1year, \"1year_broke up\")\n",
        "ss1year = ss1year.drop(['target'], axis = 1)\n",
        "\n",
        "print(\"2 year test Hetero\")\n",
        "NaiveBayesBer(hetero2year, \"2year_broke up\")\n",
        "hetero2year = hetero2year.drop(['target'], axis = 1)\n",
        "\n",
        "\n",
        "print(\"2 year test SS\")\n",
        "NaiveBayesBer(ss2year, \"2year_broke up\")\n",
        "ss2year = ss2year.drop(['target'], axis = 1)\n",
        "\n",
        "ss1year = testing1dataset.loc[(testing1dataset['same-sex couple'] == 1)]\n",
        "hetero1year = testing1dataset.loc[(testing1dataset['same-sex couple'] == 0)]\n",
        "\n",
        "\n",
        "ss2year = testing2dataset.loc[(testing2dataset['same-sex couple'] == 1)]\n",
        "hetero2year = testing2dataset.loc[(testing2dataset['same-sex couple'] == 0)]\n",
        "\n",
        "print(\"Decision Tree Model For 1 Year Break Up\")\n",
        "Xinput = testing1dataset.drop(columns=['1year_broke up'])\n",
        "yinput =  testing1dataset['1year_broke up']\n",
        "aval = .002\n",
        "DTmodel(Xinput, yinput, aval, .85, .98)\n",
        "\n",
        "print(\"Decision Tree Model For 2 Year Break Up\")\n",
        "Xinput = testing2dataset.drop(columns=['2year_broke up'])\n",
        "yinput =  testing2dataset['2year_broke up']\n",
        "aval = .0021\n",
        "DTmodel(Xinput, yinput, aval, .7, .9)\n",
        "\n",
        "RUN k nearest neighbors for test1dataset\n",
        "\n",
        "RunKnearest(testing1dataset, '1year_broke up')\n",
        "\n",
        "RUN k nearest neighbors for test2dataset\n",
        "\n",
        "RunKnearest(testing2dataset, '2year_broke up')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}